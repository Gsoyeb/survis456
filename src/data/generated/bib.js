const generatedBibEntries = {
    "7519263": {
        "abstract": "Chicken eggs are a common ingredient in human food, used as an ingredient in almost every food culture worldwide. Judging the size, and therefore weight, of an egg is often important in many food recipes. This paper proposes an image processing algorithm for classifying eggs by size from an image displayed on an Android device. A coin of known size is used in the image as a reference object. The coin's radius and the egg's dimensions are automatically detected and measured using image processing techniques. Egg sizes are classified based on their features computed from the measured dimensions using a support vector machine (SVM) classifier. The experimental results show the measurement errors in egg dimensions were low at 3.1% and the overall accuracy of size classification was 80.4%.",
        "author": "Waranusast, Rattapoom and Intayod, Pongsakorn and Makhod, Donlaya",
        "booktitle": "2016 Fifth ICT International Student Project Conference (ICT-ISPC)",
        "doi": "10.1109/ICT-ISPC.2016.7519263",
        "issn": "",
        "keywords": "type:egg size; classification; image processing; svm",
        "month": "May",
        "number": "09",
        "pages": "170-173",
        "publisher": "IEEE",
        "title": "Egg size classification on Android mobile devices using image processing and machine learning",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2016"
    },
    "7727519": {
        "abstract": "The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering, a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful features. On the other hand, deep learning can extract and organize the discriminative information from the data, not requiring the design of feature extractors by a domain expert. Convolutional Neural Networks (CNNs) are a particular type of deep, feedforward network that have gained attention from research community and industry, achieving empirical successes in tasks such as speech recognition, signal processing, object recognition, natural language processing and transfer learning. In this paper, we conduct some preliminary experiments using the deep learning approach to classify breast cancer histopathological images from BreaKHis, a publicly dataset available at http://web.inf.ufpr.br/vri/breast-cancer-database. We propose a method based on the extraction of image patches for training the CNN and the combination of these patches for final classification. This method aims to allow using the high-resolution histopathological images from BreaKHis as input to existing CNN, avoiding adaptations of the model that can lead to a more complex and computationally costly architecture. The CNN performance is better when compared to previously reported results obtained by other machine learning models trained with hand-crafted textural descriptors. Finally, we also investigate the combination of different CNNs using simple fusion rules, achieving some improvement in recognition rates.",
        "author": "Spanhol, Fabio Alexandre and Oliveira, Luiz S. and Petitjean, Caroline and Heutte, Laurent",
        "booktitle": "2016 International Joint Conference on Neural Networks (IJCNN)",
        "doi": "10.1109/IJCNN.2016.7727519",
        "issn": "2161-4407",
        "keywords": "type:Breast Cancer, CNN, stochastic descent gradient",
        "month": "July",
        "number": " 07",
        "pages": "2560-2567",
        "publisher": "IEEE",
        "title": "Breast cancer histopathological image classification using Convolutional Neural Networks",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2016"
    },
    "7780459": {
        "abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
        "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
        "booktitle": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
        "doi": "10.1109/CVPR.2016.90",
        "issn": "1063-6919",
        "keywords": "type:Keywords-deep learning, stochastic gradient descent, ResNet, imageclassification.",
        "month": "June",
        "number": " 02",
        "pages": "770-778",
        "publisher": "IEEE",
        "title": "Deep Residual Learning for Image Recognition",
        "type": "INPROCEEDINGS",
        "url": "https://ieeexplore.ieee.org/document/7780459",
        "volume": "",
        "year": "2016"
    },
    "8837044": {
        "abstract": "Breast cancer is the more prevalent form of cancer among women, and the most common type of breast cancer is the invasive ductal carcinoma (IDC). Accurate identification and categorization of breast cancer subtypes have major importance in clinical tasks, and automated approaches are relevant in saving time and reducing error. Deep learning has been applied to several breast cancer detection tasks. It outperformed traditional approaches that include handcrafted features for data representation and machine learning methods for learning task. In this paper, we develop a deep learning architecture for the prediction of IDC. This study trained an improved CNN network and investigated the performance of the model on the IDC patch-based classification task. Experimental results show that our approach yields the best performance on the IDC dataset when compared to other published approaches. Our model achieves f-score of 85.28% and balanced accuracy of 85.41% with increase improvementof11.51% on f-score and 0.86% on balanced accuracy against the latest published deep learning approach on IDC detection.",
        "author": "Romano, Aiza M. and Hernandez, Alexander A.",
        "booktitle": "2019 2nd International Conference on Artificial Intelligence and Big Data (ICAIBD)",
        "doi": "10.1109/ICAIBD.2019.8837044",
        "issn": "",
        "keywords": "type:deep learning; convolutional neural network; breat cancer; invasive ductal carcinoma prediction",
        "month": "May",
        "number": "05 05",
        "pages": "142-148",
        "publisher": "IEEE",
        "title": "Enhanced Deep Learning Approach for Predicting Invasive Ductal Carcinoma from Histopathology Images",
        "type": "INPROCEEDINGS",
        "url": "https://www.semanticscholar.org/paper/Enhanced-Deep-Learning-Approach-for-Predicting-from-Romano-Hernandez/37f65d98c5b5466b63c94a5c83c504b82786f23b",
        "volume": "",
        "year": "2019"
    },
    "9946916": {
        "abstract": "Covid_19 pandemic is considered a global emergency that has caused great human as well as economic loss. To attack this pandemic, we developed a convolutional neural network model (CNN) the detection of COVID-19 using Chest X-Ray images (CXR). The model is then deployed on the Android app RT2022 which is tested on real CXR images and the first results obtained, after experiments, testify to the performance of the RT2022 model. In COVID-19 detection, we achieved an accuracy of 90.60%",
        "author": "Mellal, Na\u00e7ima and Bouzekri, Khawla and Sabri, Meriem and Abdennebi, Salah",
        "booktitle": "2022 4th International Conference on Pattern Analysis and Intelligent Systems (PAIS)",
        "doi": "10.1109/PAIS56586.2022.9946916",
        "issn": "",
        "keywords": "type:COVID-19, CNN, Chest X-Ray Images, Android",
        "month": "Oct",
        "number": "10",
        "pages": "1-6",
        "publisher": "IEEE",
        "title": "Android App based on CNN for Covid-19 Detection using Chest X-ray Images",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2022"
    },
    "BARSHA2021104931": {
        "abstract": "Invasive ductal carcinoma (IDC) breast cancer is a significant health concern for women all around the world and early detection of the disease may increase the survival rate in patients. Therefore, Computer-Aided Diagnosis (CAD) based systems can assist pathologists to detect the disease early. In this study, we present an ensemble model to detect IDC using DenseNet-121 and DenseNet-169 followed by test time augmentation (TTA). The model achieved a balanced accuracy of 92.70% and an F1-score of 95.70% outperforming the current state-of-the-art. Comparative analysis against various pre-trained deep learning models and preprocessing methods have been carried out. Qualitative analysis has also been conducted on the test dataset. After the detection of IDC breast cancer, it is important to grade it for further treatment. In our study, we also propose an ensemble model for the grading of IDC using the pre-trained DenseNet-121, DenseNet-201, ResNet-101v2, and ResNet-50 architectures. The model is inferred from two validation cohorts. For the patch-level classification, the model yielded an overall accuracy of 69.31%, 75.07%, 61.85%, and 60.50% on one validation cohort and 62.44%, 79.14%, 76.62%, and 71.05% on the second validation cohort for 4\u00d7, 10\u00d7, 20\u00d7, and 40\u00d7 magnified images respectively. The same architecture is further validated using a different IDC dataset where it achieved an overall accuracy of 90.07%. The performance of the models on the detection and grading of IDC shows that they can be useful to help pathologists detect and grade the disease.",
        "author": "Nusrat Ameen Barsha and Aimon Rahman and M.R.C. Mahdy",
        "doi": "https://doi.org/10.1016/j.compbiomed.2021.104931",
        "issn": "0010-4825",
        "journal": "Computers in Biology and Medicine",
        "keywords": "type:Breast cancer, Invasive ductal carcinoma, Deep learning",
        "number": "03",
        "pages": "104931",
        "title": "Automated detection and grading of Invasive Ductal Carcinoma breast cancer using ensemble of deep learning models",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0010482521007253",
        "volume": "139",
        "year": "2021"
    },
    "CELIK2020232": {
        "abstract": "Advances in artificial intelligence technologies have made it possible to obtain more accurate and reliable results using digital images. Due to the advances in digital histopathological images obtained using whole slide image (WSI) scanners, automated analysis of digital images by computer support systems has become interesting. In particular, deep learning architectures, are one of the preferred approaches in the analysis of digital histopathology images. The deeper networks trained on large amounts of image data are adapted for different tasks using transfer learning technique. In this study, automated detection of invasive ductal carcinoma (IDC), which is the most common subtype of breast cancers, is proposed using deep transfer learning technique. We have used deep learning pre-trained models, ResNet-50 and DenseNet-161 for the IDC detection task. The public histopathology dataset containing 277,524 image patches were used in our experimental studies. As a result of training on the last layers of pre-trained deep networks, DenseNet-161 model has yielded F-sore of 92.38% and balanced accuracy value of 91.57%. Similarly, we have obtained F-score of 94.11% and balanced accuracy value of 90.96% using ResNet-50 architecture. In addition, our developed model is validated using the publicly available BreakHis breast cancer dataset and obtained promising results in classifying magnification independent histopathology images into benign and malignant classes. Our developed system obtained the highest classification performance as compared to the state-of-art techniques and is ready to be tested with more diverse huge databases.",
        "author": "Yusuf Celik and Muhammed Talo and Ozal Yildirim and Murat Karabatak and U Rajendra Acharya",
        "doi": "https://doi.org/10.1016/j.patrec.2020.03.011",
        "issn": "0167-8655",
        "journal": "Pattern Recognition Letters",
        "keywords": "type:Invasive ductal carcinoma, Whole slide images, Deep learning, Transfer learning",
        "number": "04",
        "pages": "232-239",
        "title": "Automated invasive ductal carcinoma detection based using deep transfer learning with whole-slide images",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S0167865520300891",
        "volume": "133",
        "year": "2020"
    },
    "article": {
        "abstract": "Real-time grasp detection plays a key role in manipulation, and it is also a complex task, especially for detecting how to grasp novel objects. This paper proposes a very quick and accurate approach to detect robotic grasps. The main idea is to perform grasping of novel objects in a typical RGB-D scene view. Our goal is not to find the best grasp for every object but to obtain the local optimal grasps in candidate grasp rectangles. There are three main contributions to our detection work. Firstly, an improved graph segmentation approach is used to do objects detection and it can separate objects from the background directly and fast. Secondly, we develop a morphological image processing method to generate candidate grasp rectangles set which avoids us to search grasp rectangles globally. Finally, we train a random forest model to predict grasps and achieve an accuracy of 94.26%. The model is mainly used to score every element in our candidate grasps set and the one gets the highest score will be converted to the final grasp configuration for robots. For real-world experiments, we set up our system on a tabletop scene with multiple objects and when implementing robotic grasps, we control Baxter robot with a different inverse kinematics strategy rather than the built-in one.",
        "author": "Zhang, Jiahao and Li, Miao and Feng, Ying and Yang, Chenguang",
        "doi": "10.1007/s11042-019-08302-9",
        "journal": "Multimedia Tools and Applications",
        "keywords": "type:Real-time grasp detection, Novel objects, Improved graph segmentation method, Morphological image processing, Random forest, Baxter",
        "month": "01",
        "number": "08",
        "pages": "",
        "title": "Robotic grasp detection based on image processing and random forest",
        "type": "article",
        "volume": "79",
        "year": "2020"
    },
    "inproceedings": {
        "abstract": "The study introduces a new pooling scheme calledAccept-Reject Pooling which uses a stochastic procedure andintegration of a rejection sampling based method of selectionfrom a multinomial distribution of the pooling region\u2019sactivations. The stochastic component of the proposed poolingoperation ensures that non-maximal activations will have achance to be selected and passed to the network while ensuringthat the strong activations get the higher chance of beingsampled. Experiments demonstrate that the approach can alsowork well with other techniques such as Batch Normalizationand Data Augmentation Convolutional Neural Networkachieve improved performance with Accept-Reject Pooling ascompared to the use of several pooling methods such as max,stochastic and mixed pooling on benchmark imageclassification datasets.",
        "author": "Romano, Aiza and Hernandez, Alexander",
        "doi": "10.1109/ICICN.2019.8834960",
        "keywords": "type:Keywords-deep learning, convolutional neural network,accept-reject pooling, improved stochastic pooling, imageclassification.",
        "month": "04",
        "number": "01",
        "pages": "201-206",
        "publisher": "IEEE",
        "title": "An Improved Pooling Scheme for Convolutional Neural Networks",
        "type": "inproceedings",
        "url": "https://www.researchgate.net/publication/335794896_An_Improved_Pooling_Scheme_for_Convolutional_Neural_Networks",
        "year": "2019"
    },
    "pmlr-v37-ioffe15": {
        "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer\u2019s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.",
        "address": "Lille, France",
        "author": "Ioffe, Sergey and Szegedy, Christian",
        "booktitle": "Proceedings of the 32nd International Conference on Machine Learning",
        "editor": "Bach, Francis and Blei, David",
        "keywords": "type:deep learning, batch normalisation, internal covariate shift",
        "month": "07--09 Jul",
        "number": "06",
        "pages": "448--456",
        "pdf": "http://proceedings.mlr.press/v37/ioffe15.pdf",
        "publisher": "PMLR",
        "series": "Proceedings of Machine Learning Research",
        "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
        "type": "InProceedings",
        "url": "https://proceedings.mlr.press/v37/ioffe15.html",
        "volume": "37",
        "year": "2015"
    }
};